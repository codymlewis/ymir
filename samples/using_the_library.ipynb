{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Library\n",
    "\n",
    "In this document, we will look at using the library for a few standard federated learning environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 10:56:17.658407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-20 10:56:17.658431: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#%pip install -U git+https://github.com/codymlewis/ymir.git git+https://github.com/codymlewis/tenjin.git tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tenjin\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import ymir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first look standard federated learning. We will write a function to create a keras model as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, output_shape, lr=0.1):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = tf.keras.layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(output_shape, activation=\"softmax\")(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(loss=loss_fn, optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the MNIST dataset, define the per-client batch sizes and perform a latent Dirichlet allocation (LDA) on the dataset.\n",
    "\n",
    "Finally, we will create separate validation and test datasets to evaluate the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "dataset = ymir.mp.datasets.Dataset(*tenjin.load('mnist'))\n",
    "batch_sizes = [32 for _ in range(num_clients)]\n",
    "data = dataset.fed_split(batch_sizes, ymir.mp.distributions.lda)\n",
    "train_eval = dataset.get_iter(\"train\", 10_000)\n",
    "test_eval = dataset.get_iter(\"test\", 10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the network and clients, adding each client to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:02:19.300739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-20 11:02:19.300782: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-20 11:02:19.300809: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cmla): /proc/driver/nvidia/version does not exist\n",
      "2022-04-20 11:02:19.301089: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "network = ymir.mp.network.Network()\n",
    "for d in data:\n",
    "    network.add_client(ymir.regiment.Scout(create_model(dataset.input_shape, dataset.classes), d, 1, test_data=test_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the federated learning global model and controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ymir.garrison.fedavg.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform federated learning by repeatedly calling the `step` method on the controller. There will likely be retracing warnings,\n",
    "these arise due to calling training steps on each client independently, cause a tracing step for each one, this does not impact\n",
    "performance.\n",
    "\n",
    "In the following we also, periodically evaluate the global model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2abfb863764e76b243577f74d3b08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Learning Methods\n",
    "\n",
    "In this library, we include a number of alternative methods for federated learning. In the following, we will cover the most notable.\n",
    "\n",
    "## Different Aggregators\n",
    "\n",
    "Using a different aggregator is as simple as using a different Captain object either from the `garrison` module or by a class that\n",
    "inherits from `Captain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ymir.garrison.median.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do the learning loop as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f488fca505d45b3a58038eddbdc3ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Learning\n",
    "\n",
    "Personalized learning methods require the construction of a different client within the network, one that does not overwrite\n",
    "the local model weights with the global model weights.\n",
    "\n",
    "In the following example we will construct a network of ditto personalized learners and apply federated averaging for aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:14:37.501637: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://244af4cf-3002-4833-b62e-55b7bb50e98f/assets\n",
      "INFO:tensorflow:Assets written to: ram://cfc071f1-95dd-41d9-88c3-e203e157e8e1/assets\n",
      "INFO:tensorflow:Assets written to: ram://11e5875e-f0ab-44c6-9d0f-e1916299a8a5/assets\n",
      "INFO:tensorflow:Assets written to: ram://d6e9f232-d748-4af8-87d9-758981256b72/assets\n",
      "INFO:tensorflow:Assets written to: ram://aebe4237-afa8-4025-9777-b2bae1c93043/assets\n",
      "INFO:tensorflow:Assets written to: ram://9e491cb2-c7ce-4c13-b5c0-64b5d1e9e4bd/assets\n",
      "INFO:tensorflow:Assets written to: ram://d935f5a7-c653-4aba-bbcd-48d17a53aa59/assets\n",
      "INFO:tensorflow:Assets written to: ram://4f02eb2a-27a8-4b41-a20e-d4c26a243444/assets\n",
      "INFO:tensorflow:Assets written to: ram://180a8e6a-cb61-4114-9d97-55791fab2796/assets\n",
      "INFO:tensorflow:Assets written to: ram://b4e3f388-96bc-4fcc-8b50-84defc5d4154/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c277b68f99e4b3b8e85d668aa721a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Scout._local_step at 0x7fe9782d8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Scout._global_step at 0x7fe924fd4ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Scout._local_step at 0x7fe924fd4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Scout._global_step at 0x7fe978579630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "network = ymir.mp.network.Network()\n",
    "for d in data:\n",
    "    network.add_client(ymir.regiment.ditto.Scout(create_model(dataset.input_shape, dataset.classes), d, 1, test_data=test_eval))\n",
    "learner = ymir.garrison.fedavg.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)\n",
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal Terms/FL Regularization"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
