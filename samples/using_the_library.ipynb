{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Library\n",
    "\n",
    "In this document, we will look at using the library for a few standard federated learning environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U git+https://github.com/codymlewis/ymir.git git+https://github.com/codymlewis/tenjin.git tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tenjin\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import ymir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first look standard federated learning. We will write a function to create a keras model as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, output_shape, lr=0.1):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = tf.keras.layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(output_shape, activation=\"softmax\")(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(loss=loss_fn, optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the MNIST dataset, define the per-client batch sizes and perform a latent Dirichlet allocation (LDA) on the dataset.\n",
    "\n",
    "Finally, we will create separate validation and test datasets to evaluate the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "dataset = ymir.mp.datasets.Dataset(*tenjin.load('mnist'))\n",
    "batch_sizes = [32 for _ in range(num_clients)]\n",
    "data = dataset.fed_split(batch_sizes, ymir.mp.distributions.lda)\n",
    "train_eval = dataset.get_iter(\"train\", 10_000)\n",
    "test_eval = dataset.get_iter(\"test\", 10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the network and clients, adding each client to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ymir.mp.network.Network()\n",
    "for d in data:\n",
    "    network.add_client(ymir.regiment.Scout(create_model(dataset.input_shape, dataset.classes), d, 1, test_data=test_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the federated learning global model and controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ymir.garrison.fedavg.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform federated learning by repeatedly calling the `step` method on the controller. There will likely be retracing warnings,\n",
    "these arise due to calling training steps on each client independently, cause a tracing step for each one, this does not impact\n",
    "performance.\n",
    "\n",
    "In the following we also, periodically evaluate the global model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Learning Methods\n",
    "\n",
    "In this library, we include a number of alternative methods for federated learning. In the following, we will cover the most notable.\n",
    "\n",
    "## Different Aggregators\n",
    "\n",
    "Using a different aggregator is as simple as using a different Captain object either from the `garrison` module or by a class that\n",
    "inherits from `Captain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ymir.garrison.median.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do the learning loop as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized/Proximal Learning\n",
    "\n",
    "Learning using clients with proximal or regularized terms amounts to adding a different client type to the network, these clients\n",
    "have a different local step function that adds the term as a penalty to the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ymir.mp.network.Network()\n",
    "for d in data:\n",
    "    network.add_client(ymir.regiment.fedmax.Scout(create_model(dataset.input_shape, dataset.classes), d, 1, test_data=test_eval))\n",
    "learner = ymir.garrison.fedavg.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)\n",
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Learning\n",
    "\n",
    "Personalized learning methods require the construction of a different client within the network, one that does not overwrite\n",
    "the local model weights with the global model weights.\n",
    "\n",
    "In the following example we will construct a network of ditto personalized learners and apply federated averaging for aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ymir.mp.network.Network()\n",
    "for d in data:\n",
    "    network.add_client(ymir.regiment.ditto.Scout(create_model(dataset.input_shape, dataset.classes), d, 1, test_data=test_eval))\n",
    "learner = ymir.garrison.fedavg.Captain(create_model(dataset.input_shape, dataset.classes, lr=1), network)\n",
    "for r in (pbar := trange(500)):\n",
    "    loss = learner.step()\n",
    "    if r % 10 == 0:\n",
    "        metrics = learner.model.test_on_batch(*next(test_eval), return_dict=True)\n",
    "        pbar.set_postfix(metrics)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
