{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9714c593",
   "metadata": {},
   "source": [
    "# Using the Library\n",
    "\n",
    "In this document we will look at the basics of using the aesir library.\n",
    "\n",
    "First we will install and import the libraries in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39d5572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 17:12:15.187578: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-28 17:12:15.187595: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets einops flax numpy optax tqdm git+https://github.com/codymlewis/ymir.git\n",
    "\n",
    "import datasets\n",
    "import einops\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import ymir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abedcd79",
   "metadata": {},
   "source": [
    "Next we define our neural network model, in the following we use the [flax library](https://github.com/google/flax) but many other JAX libraries should be compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fcb988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.Sequential(\n",
    "            [\n",
    "                lambda x: einops.rearrange(x, \"b w h c -> b (w h c)\"),\n",
    "                nn.Dense(300), nn.relu,\n",
    "                nn.Dense(100), nn.relu,\n",
    "                nn.Dense(10), nn.softmax\n",
    "            ]\n",
    "        )(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbe18c",
   "metadata": {},
   "source": [
    "Now we define out evaluation functions, first cross entropy loss, then accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd48acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(model):\n",
    "\n",
    "    @jax.jit\n",
    "    def _loss(params, X, y):\n",
    "        logits = jnp.clip(model.apply(params, X), 1e-15, 1 - 1e-15)\n",
    "        one_hot = jax.nn.one_hot(y, logits.shape[-1])\n",
    "        return -jnp.mean(jnp.einsum(\"bl,bl -> b\", one_hot, jnp.log(logits)))\n",
    "\n",
    "    return _loss\n",
    "\n",
    "\n",
    "def accuracy(model, params, X, y):\n",
    "    return jnp.mean(jnp.argmax(model.apply(params, X), axis=-1) == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae85d80",
   "metadata": {},
   "source": [
    "This next we preprocess our data. This library uses [huggingface datasets](https://huggingface.co/docs/datasets/) with the features in the `X` column and the labels in the `Y` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977c826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mnist (/home/cody/.cache/huggingface/datasets/mnist/mnist/1.0.0/fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84eb52451744ffaaf2f8edaf95376a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb395a3a91c14ddc9c62fe6de1f99b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce385f91ae5c463abc8dd8e3a341c093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6172e52728428cb24d99ec0d145e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e6c2741f3d422cb81340f96f85b513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset('mnist')\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    result = {}\n",
    "    result['X'] = einops.rearrange(np.array(examples['image'], dtype=np.float32) / 255, \"h (w c) -> h w c\", c=1)\n",
    "    result['Y'] = examples['label']\n",
    "    return result\n",
    "\n",
    "ds = ds.map(preprocess_data, remove_columns=['image', 'label'])\n",
    "features = ds['train'].features\n",
    "features['X'] = datasets.Array3D(shape=(28, 28, 1), dtype='float32')\n",
    "ds['train'] = ds['train'].cast(features)\n",
    "ds['test'] = ds['test'].cast(features)\n",
    "ds.set_format('numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa3113",
   "metadata": {},
   "source": [
    "Next we set up our data into a federated learning dataset and distribute across our clients according to latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4391dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "dataset = aesir.utils.datasets.Dataset(ds)\n",
    "batch_sizes = [32 for _ in range(num_clients)]\n",
    "data = dataset.fed_split(batch_sizes, aesir.utils.distributions.lda)\n",
    "test_eval = dataset.get_iter(\"test\", 10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab994e",
   "metadata": {},
   "source": [
    "Then we set up the initial global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d28a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "params = model.init(jax.random.PRNGKey(42), np.zeros((32,) + dataset.input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1828b2",
   "metadata": {},
   "source": [
    "Now we set up the network, we first construct the Network object add our clients, then place the network into a Server object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d49420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = aesir.utils.network.Network()\n",
    "for d in data:\n",
    "    network.add_client(aesir.client.Client(params, optax.sgd(0.1), ce_loss(model.clone()), d))\n",
    "server = aesir.server.fedavg.Server(network, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f60103",
   "metadata": {},
   "source": [
    "Finally, we perform our rounds of training simply by repeatedly calling the step function from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe154a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2904e376abe04665ac19f05b91d4c994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r in (p := trange(3750)):\n",
    "    loss_val = server.step()\n",
    "    p.set_postfix_str(f\"loss: {loss_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49908b6",
   "metadata": {},
   "source": [
    "We conclude by looking out how this final model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab73a8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.080\n",
      "Test accuracy: 97.550%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test loss: {ce_loss(model)(server.params, *next(test_eval)):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy(model, server.params, *next(test_eval)):.3%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
